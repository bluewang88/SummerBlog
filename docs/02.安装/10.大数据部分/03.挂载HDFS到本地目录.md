---
title: 挂载HDFS到本地目录
date: 2021-03-05 15:16:20
permalink: /pages/ea7c2e/
categories:
  - 安装
  - 大数据部分
tags:
  - hadoop
  - HDFS
---

Hadoop新特性：支持通过NFSv3挂载HDFS文件系统到用户的本地文件目录；也就是说：允许用户像访问本地文件系统一样访问HDFS！这对于普通用户来说大大的简化了HDFS的使用。summer记录下如何将HDFS文件系统挂载到Linux本地中。

<!-- more -->

## 1.部署架构图

![](https://cdn.jsdelivr.net/gh/summerking1/image@main/0305-2.png)

## 2.实现效果

1. 用户可以浏览HDFS文件系统通过本地的文件系统。
2. 用户可以下载HDFS文件在本地文件系统。
3. 用户可以直接上传文件从本地文件系统到hdfs。
4. 用户可以通过挂载点将数据直接流到HDFS。

## 3.部署详解

> 这里使用2台主机举例：一台作为hadoop文件系统HDFS，另外1台作为客户机挂载HDFS到本地文件系统。

主机 | 主机名 | IP
--|--|--
HDFS服务器 |	Master	| 192.168.0.95
PC1客户端  | 	Node1	| 192.168.0.96

## 4.HDFS服务端操作

1. 先停止HDFS服务端

```shell
[root@master sbin]# ./stop-dfs.sh 
Stopping namenodes on [apiserver.cluster.local]
apiserver.cluster.local: stopping namenode
localhost: stopping datanode
Stopping secondary namenodes [0.0.0.0]
0.0.0.0: stopping secondarynamenode
[root@master sbin]# jps
9150 Jps
```

2. 编辑配置文件
```shell
[root@master sbin]# cd ../etc/hadoop/
[root@master hadoop]# vim hdfs-site.xml 
<configuration>
      <property>
         <name>dfs.replication</name>
         <value>1</value>
      </property>
      <property>
        <name>dfs.namenode.accesstime.precision</name>
        <value>3600000</value>
        <description>The access time for HDFS file is precise upto this value. The default value is 1 hour.
        Setting a value of 0 disables access times for HDFS.
        </description>
     </property>
     <property>
        <name>nfs.dump.dir</name>
        <value>/tmp/.hdfs-nfs</value>
     </property>
     <property>
        <name>nfs.exports.allowed.hosts</name>
        <value>* rw</value>
     </property>
</configuration>
[root@master hadoop]# vim core-site.xml 
[root@master hadoop]# cat core-site.xml 
<!-- Put site-specific property overrides in this file. -->
<configuration>
     <property>
         <name>fs.defaultFS</name>
         <value>hdfs://192.168.0.95:9000</value>             
     </property>
     <!-- 指定hadoop临时目录 -->
     <property>
         <name>hadoop.tmp.dir</name>
         <value>/home/summer/hadoop/data/tmp</value>
     </property>
     <property>
         <name>hadoop.proxyuser.root.groups</name>
         <value>*</value>
     </property>
     <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>
     </property>
</configuration>
[root@master hadoop]# 

```


3. 启动HDFS的NFS

> 启动NFS一共有三个守护进程，分别为 portmap，mountd和nfsd，NFS网关进程同时具有nfsd和mountd。这里我利用Hadoop自带的包启动

```shell
[root@master hadoop]# service nfs stop  //停止平台提供的nfs/rpcbind/portmap服务
Redirecting to /bin/systemctl stop nfs.service
[root@master hadoop]# service rpcbind stop
Redirecting to /bin/systemctl stop rpcbind.service
Warning: Stopping rpcbind.service, but it can still be activated by:
  rpcbind.socket
[root@master hadoop]# cd ../../sbin/
[root@master sbin]# ./start-dfs.sh   //启动hdfs文件系统
Starting namenodes on [apiserver.cluster.local]
apiserver.cluster.local: starting namenode, logging to /summer/hadoop/logs/hadoop-root-namenode-master.out
localhost: starting datanode, logging to /summer/hadoop/logs/hadoop-root-datanode-master.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /summer/hadoop/logs/hadoop-root-secondarynamenode-master.out
[root@master sbin]# jps  //验证进程是否启动
88064 SecondaryNameNode
87028 DataNode
89551 Jps
86446 NameNode
[root@master sbin]# ./hadoop-daemon.sh start portmap  //启动包含portmap的包(需要root权限):
starting portmap, logging to /summer/hadoop/logs/hadoop-root-portmap-master.out
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.
[root@master sbin]# jps  //验证portmap进程
88064 SecondaryNameNode
87028 DataNode
93229 Jps
86446 NameNode
92350 Portmap
[root@master sbin]# ./hadoop-daemon.sh start nfs3  //启动 mountd and nfsd进程
starting nfs3, logging to /summer/hadoop/logs/hadoop-root-nfs3-master.out
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.
[root@master sbin]# jps  //验证nfs3进程
88064 SecondaryNameNode
94704 Nfs3
95650 Jps
87028 DataNode
86446 NameNode
92350 Portmap
[root@master sbin]# rpcinfo -p 192.168.0.95  //验证所有服务是否已启动和运行
   program vers proto   port  service
    100005    3   udp   4242  mountd
    100005    1   tcp   4242  mountd
    100000    2   udp    111  portmapper
    100000    2   tcp    111  portmapper
    100005    3   tcp   4242  mountd
    100005    2   tcp   4242  mountd
    100003    3   tcp   2049  nfs
    100005    2   udp   4242  mountd
    100005    1   udp   4242  mountd
[root@master sbin]# showmount -e 192.168.0.95  //验证HDFS的namespace是否导出并可以挂载。
Export list for 192.168.0.95:
/ *
[root@master sbin]#
```

## 5.本机挂载

- 创建目录并挂载

```shell
[root@master sbin]# mkdir /hdfs
[root@master sbin]# mount -t nfs -o vers=3,proto=tcp,nolock,noacl 192.168.0.95:/ /hdfs/
[root@master sbin]# df -h
文件系统                 容量  已用  可用 已用% 挂载点
/dev/mapper/centos-root  468G   34G  435G    8% /
devtmpfs                 7.8G     0  7.8G    0% /dev
tmpfs                    7.8G     0  7.8G    0% /dev/shm
tmpfs                    7.8G  755M  7.1G   10% /run
tmpfs                    7.8G     0  7.8G    0% /sys/fs/cgroup
/dev/sda1               1014M  142M  873M   14% /boot
/dev/mapper/centos-home   24G  257M   24G    2% /home
tmpfs                    1.6G     0  1.6G    0% /run/user/1000
tmpfs                    1.6G     0  1.6G    0% /run/user/0
192.168.0.95:/           468G   34G  435G    8% /hdfs
[root@master sbin]# 
```

## 6.跨机器挂载

>这里模拟node1（192.168.0.96）挂载远端HDFS文件系统（192.168.0.95）

```shell
[root@node1 mnt]# showmount -e 192.168.0.95
Export list for 192.168.0.95:
/ *
[root@node1 mnt]# mount 192.168.0.95:/ /mnt/
[root@node1 mnt]#
```

## 7.双向验证

> 在95机器（hdfs文件系统中）创建文件，验证96机器挂载点是否同步生成文件或文件夹
> 具体操作如下：

```shell
[root@master sbin]# hdfs dfs -mkdir /user
[root@master sbin]# hdfs dfs -mkdir /user/test
[root@master sbin]# hdfs dfs -ls /
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-03-05 14:23 /user
[root@master sbin]# hdfs dfs -ls /user
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-03-05 14:23 /user/test
[root@master sbin]# cd /hdfs/
[root@master hdfs]# ls
user
[root@master hdfs]# ll
总用量 1
drwxr-xr-x 3 root 2584148964 96 3月   5 14:23 user
[root@master hdfs]# cd user/
[root@master user]# ls
test
[root@master user]# 
```


>可以查看96上机器挂载点上同步生成了文件

```shell
[root@node1 mnt]# cd /mnt/
[root@node1 mnt]# ll
总用量 1
drwxr-xr-x 3 root 2584148964 96 3月   5 14:23 user
[root@node1 mnt]# cd user/
[root@node1 user]# ll
总用量 1
drwxr-xr-x 2 root 2584148964 64 3月   5 14:23 test
[root@node1 user]#
```

> 在96机器挂载点上创建文件或文件夹，验证95机器（hdfs文件系统中）是否同步生成文件
> 这里96创建一个文件

```shell
[root@node1 user]# touch 1234.sh
[root@node1 user]# ll
总用量 1
-rw-r--r-- 1 root root        0 3月   5 14:31 1234.sh
drwxr-xr-x 2 root 2584148964 64 3月   5 14:23 test
[root@node1 user]# 
```

> 可以查看95机器hdfs文件系统同步生成了一个文件

```shell
[root@master user]# hdfs dfs -ls /user
Found 2 items
-rw-r--r--   1 root root                0 2021-03-05 14:31 /user/1234.sh
drwxr-xr-x   - root supergroup          0 2021-03-05 14:23 /user/test
[root@master user]# 
```

> 这里模拟上传文件夹到96挂载点上

```shell
[root@node1 summer]# mv elasticsearch_cluster/ /mnt/
[root@node1 summer]# cd /mnt/
[root@node1 mnt]# ls
elasticsearch_cluster  user
[root@node1 mnt]# 
```

> 可以查看95机器hdfs文件系统中同步了该文件

```shell
[root@master user]# hdfs dfs -ls /
Found 2 items
drwxr-xr-x   - summer summer          0 2021-01-28 18:10 /elasticsearch_cluster
drwxr-xr-x   - root        supergroup           0 2021-03-05 14:31 /user
[root@master user]# 
```

> 也可通过浏览器直观查看

![](https://cdn.jsdelivr.net/gh/summerking1/image@main/0305-3.png)